{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mb26-code/ter-rel-sem/blob/main/Extraction_relations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK2_nix4F06c"
      },
      "source": [
        "# Explication de l'algo\n",
        "Je crée une classe `TokenAnnotation` pour traiter chaque token (mot). Cette classe est pour but de stocker des infos du token lui-même, comme :\n",
        "- text : texte brut\n",
        "- lemma : texte après traitement\n",
        "- pos : nature du mot (adj, adv, nom)\n",
        "- dep : label de dépendence, pour définir sa relation avec un autre token (head) dans la phrase, comme `nsubj` --> nominal subject\n",
        "- head : indice de `head` de ce token. Càd ce token est le dépendent de head\n",
        "\n",
        "Ultérieurement, on va se baser sur cette `dep` pour filtrer quelles dépendences qu'on prendra pour tester avec l'API JdM, au lieu de brute-force tous les cas inutiles.\n",
        "\n",
        "Par exemple, prenons cette phrase :\n",
        "**Le bouillon contient traditionnellement un oignon piqué de clous de girofle, l'ail est déconseillé.**\n",
        "\n",
        "Après l'extraction, `girofle` a son head `clou` et sa dep `nmod`.\n",
        "```\n",
        "head | lemma | dep\n",
        "('clou', 'girofle', 'nmod')\n",
        "```\n",
        "Vérifions avec JdM : https://jdm-api.demo.lirmm.fr/v0/relations/from/clou/to/girofle\n",
        "\n",
        "On aura 2 relations :\n",
        "\n",
        "- Type 0 : r_associated\n",
        "- Type 8 : r_hypo\n",
        "\n",
        "Donc, on sauvegardera dans la BdD cette paire et ses relations, à filtrer par le poids `w` si nécessaire.\n",
        "\n",
        "À consulter les relations types : https://jdm-api.demo.lirmm.fr/v0/relations_types#\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flg7Vide5-hw"
      },
      "source": [
        "# Filtrer par Word2Vec avant d'envoyer ces paires à JdM\n",
        "\n",
        "Word2Vec :\n",
        "1. Principe de base\n",
        "Word2Vec encode chaque mot sous forme de vecteur en se basant sur ses contexte d’apparition (les mots voisins dans un corpus), pas sur sa forme ou sa morphologie.\n",
        "2. Entraînement\n",
        "-\tSkip-Gram : pour un mot central w, le modèle apprend à prédire les mots qui l’entourent.\n",
        "-\tCBOW : pour un ensemble de mots de contexte, il prédit le mot central.\n",
        "Le résultat : deux mots qui partagent des contextes similaires (ex. “girofle” et “épice”) auront des vecteurs proches.\n",
        "3. Centroïde de domaine\n",
        "On choisit quelques pivots représentatifs du domaine (ex. “cuisine”, “recette”, “ingrédient”) et on fait la moyenne de leurs vecteurs pour obtenir un vecteur-prototype du domaine gastronomie.\n",
        "\n",
        "**--> Donc, on va créer un vecteur à partir des mots qu'on pense qu'ils sont liés à la gastronomie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGFNfGniRR3h"
      },
      "source": [
        "# Envoyer les paires récupérées ci-dessus et vérifier avec JdM\n",
        "\n",
        "`https://jdm-api.demo.lirmm.fr/v0/relations/from/[head]/to/[lemma]`\n",
        "\n",
        "https://jdm-api.demo.lirmm.fr/v0/relations/from/clou/to/girofle\n",
        "\n",
        "**Puis, sauvegarder sous format .csv pour analyser.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bia5L5L6-ZKt"
      },
      "source": [
        "# Solution complète à partir de cette cellule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EsC6b4rmBll_"
      },
      "outputs": [],
      "source": [
        "# Clean problematic packages\n",
        "!pip uninstall -y numpy spacy gensim\n",
        "\n",
        "# Reinstall only compatible versions\n",
        "!pip install numpy==1.26.4 --no-cache-dir\n",
        "!pip install spacy gensim --no-cache-dir\n",
        "\n",
        "# Download Word2Vec French model\n",
        "!wget -c \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz\" -O \"cc.fr.300.vec.gz\"\n",
        "# Download Spacy large French model\n",
        "!python -m spacy download fr_core_news_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbyIjHUzayfw",
        "outputId": "1d31ba44-05a6-4b71-feff-f8a46b320d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "my_local_drive='/content/gdrive/My Drive/TER/'\n",
        "sys.path.append(my_local_drive)\n",
        "\n",
        "PATH_RELATIONS_TYPES = f\"{my_local_drive}relations_types.json\" # Liste des relations\n",
        "PATH_PAIRS = f\"{my_local_drive}pairs.txt\" # Paires récupérées\n",
        "PATH_FILTERED_PAIRS = f\"{my_local_drive}filtered_pairs.txt\" # Paires filtrées par Word2Vec\n",
        "PATH_UNDER_PAIRS = f\"{my_local_drive}under_threshold_pairs.txt\"\n",
        "PATH_RELATIONS_RESULTS = f\"{my_local_drive}relations_results.csv\" # Résultats retournés de JdM\n",
        "\n",
        "CURR_FOLDER = \"marmiton/\" # wikipedia || marmiton\n",
        "PATH_DONNEES_BRUTES = f\"{my_local_drive}donnees_brutes/{CURR_FOLDER}\"\n",
        "PATH_OUTPUT = f\"{my_local_drive}output/{CURR_FOLDER}\"\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "import spacy\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "from numpy.linalg import norm\n",
        "from collections import defaultdict\n",
        "import glob\n",
        "import csv\n",
        "import requests, json, time\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "\n",
        "nlp = spacy.load(\"fr_core_news_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_pVwk7atftML"
      },
      "outputs": [],
      "source": [
        "# PARAMÈTRES À AJUSTER\n",
        "\n",
        "# Liste des relations qui sont capable de fournir des entités intéressantes\n",
        "INTERESTING_DEPS = {\n",
        "    # verbal relations: subject → verb, verb → object\n",
        "    \"nsubj\", \"nsubj:pass\", \"obj\", \"iobj\",\n",
        "    # noun modifiers: noun → noun (prep-headed), noun → adjective\n",
        "    \"nmod\", \"obl\",  \"amod\",    # e.g. “recette de cuisine”, “bouillon aromatique”\n",
        "    # multi-word names & appositions\n",
        "    \"compound\", \"flat:name\", \"appos\",\n",
        "    # clausal modifiers (relative/participial clauses)\n",
        "    \"acl\", \"acl:relcl\", \"advcl\",\n",
        "}\n",
        "\n",
        "# Liste des mots pour créer un vecteur représentant la gastronomie (ce qui nous intéresse)\n",
        "# pivots = [\"cuisine\",\"recette\",\"ingrédient\",\"épice\",\"gastronomie\"]\n",
        "pivots = [\n",
        "    # domaine & pratique\n",
        "    \"cuisine\", \"gastronomie\", \"cuisinier\",\n",
        "\n",
        "    # structure de la recette\n",
        "    \"recette\", \"préparation\", \"ingrédient\", \"étape\", \"temps\",\n",
        "\n",
        "    # techniques de cuisson\n",
        "    \"cuisson\", \"mijoter\", \"bouillir\", \"rôtir\", \"griller\",\n",
        "    \"sauter\", \"frire\", \"braiser\", \"cuire\",\n",
        "\n",
        "    # ustensiles & contenants\n",
        "    \"marmite\", \"casserole\", \"poêle\", \"four\", \"ustensile\",\n",
        "\n",
        "    # aromates & assaisonnements\n",
        "    \"épice\", \"condiment\", \"assaisonnement\", \"aromate\", \"bouquet_garni\",\n",
        "\n",
        "    # catégories d’aliments\n",
        "    \"viande\", \"poisson\", \"légume\", \"fruit\", \"fruit_de_mer\",\n",
        "    \"produit_laitier\", \"farine\", \"sucre\", \"sel\", \"poivre\",\n",
        "\n",
        "    # types de plats\n",
        "    \"entrée\", \"plat_principal\", \"accompagnement\", \"dessert\",\n",
        "    \"apéritif\", \"sauce\",\n",
        "\n",
        "    # nutrition & diététique\n",
        "    \"nutrition\", \"calorie\", \"diététique\"\n",
        "]\n",
        "\n",
        "# Le seuil de similarité avec le vecteur \"gastronomie\"\n",
        "THRESHOLD = 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kSXVi4hT8sUh"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TokenAnnotation:\n",
        "    text: str           # surface form\n",
        "    lemma: str          # canonical form\n",
        "    pos: str            # part-of-speech tag\n",
        "    dep: str            # dependency label\n",
        "    head: int           # index of the head token in its sentence\n",
        "    sent_id: Optional[int] = None  # optional: which sentence\n",
        "\n",
        "def annotate(text: str) -> List[List[TokenAnnotation]]:\n",
        "    doc = nlp(text)\n",
        "    all_sents: List[List[TokenAnnotation]] = []\n",
        "    for sent_id, sent in enumerate(doc.sents):\n",
        "        tokens = []\n",
        "        for token in sent:\n",
        "            tokens.append(TokenAnnotation(\n",
        "                text=token.text,\n",
        "                lemma=token.lemma_,\n",
        "                pos=token.pos_,\n",
        "                dep=token.dep_,\n",
        "                head=token.head.i - sent.start,  # index *within* this sentence\n",
        "                sent_id=sent_id\n",
        "            ))\n",
        "        all_sents.append(tokens)\n",
        "    return all_sents\n",
        "\n",
        "def extract_pairs(tokens):\n",
        "    pairs = []\n",
        "    for idx, tok in enumerate(tokens):\n",
        "        if tok.dep in INTERESTING_DEPS:\n",
        "            head = tokens[tok.head]\n",
        "            if tok.lemma in string.punctuation or head.lemma in string.punctuation:\n",
        "                continue\n",
        "            pairs.append(( head.lemma, tok.lemma, tok.dep, tok.pos ))\n",
        "    return pairs\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('cc.fr.300.vec.gz', binary=False, limit=50000)  # Limit to 50k for memory\n",
        "\n",
        "# 1. Define your gastronomy “pivot” words\n",
        "# Keep only those that actually exist in the model\n",
        "pivot_vecs = [model[p] for p in pivots if p in model]\n",
        "if not pivot_vecs:\n",
        "    raise ValueError(\"None of your pivots were in the model!\")\n",
        "\n",
        "# 2. Compute the domain centroid\n",
        "domain_centroid = np.mean(pivot_vecs, axis=0)\n",
        "\n",
        "# 4. Define helper functions\n",
        "def pair_vector(h, lemma):\n",
        "    \"\"\"Average the two word vectors.\"\"\"\n",
        "    return (model[h] + model[lemma]) / 2\n",
        "\n",
        "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    return float(a.dot(b) / (norm(a) * norm(b)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W5gyrPlY0uDN",
        "outputId": "2a0187bd-8e10-4070-f875-c0c331331bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Bouchées aux fruits de mer et quenelles.txt: 26it [00:16,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1/4969. 4968 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Moscow mule.txt: 8it [00:05,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2/4969. 4967 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Croque-monsieur allégé.txt: 22it [00:14,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3/4969. 4966 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Apéritif vin d'orange.txt: 32it [00:21,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4/4969. 4965 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Salade composé aux haricots blancs.txt: 27it [00:19,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5/4969. 4964 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Francesinhas (Portugal).txt: 36it [00:26,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6/4969. 4963 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Omble chevalier aux petits légumes.txt: 74it [00:49,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7/4969. 4962 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Têtes de pommes de terre fripées au Airfryer.txt: 30it [00:18,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8/4969. 4961 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Joues de porc en cocotte.txt: 61it [00:38,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9/4969. 4960 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Burger pulled pork raclette et confit d'oignon.txt: 22it [00:13,  1.51it/s]ERROR:root:File: Burger pulled pork raclette et confit d'oignon.txt, Pair: (Placez, sachet), Error: 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Placez/to/sachet\n",
            "Processing pairs from Burger pulled pork raclette et confit d'oignon.txt: 24it [00:14,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing pair (Placez, sachet): 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Placez/to/sachet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Burger pulled pork raclette et confit d'oignon.txt: 43it [00:25,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10/4969. 4959 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Chamallows au chocolat.txt: 20it [00:12,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11/4969. 4958 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Pop corn au micro-ondes.txt: 26it [00:14,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12/4969. 4957 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gravity cake pop-corn et caramel.txt: 154it [01:28,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13/4969. 4956 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Boudin blanc maison.txt: 58it [00:47,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14/4969. 4955 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Rognons de veau aux champignons et au porto.txt: 21it [00:12,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15/4969. 4954 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Carbonnade de porc au vinaigre.txt: 34it [00:25,  1.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16/4969. 4953 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Potimarron sans épluchage au four.txt: 21it [00:13,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17/4969. 4952 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Purée de potimarron à ma façon.txt: 45it [00:27,  1.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18/4969. 4951 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Velouté de potiron et pommes de terre au Thermomix.txt: 57it [00:36,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19/4969. 4950 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Velouté de potiron.txt: 32it [00:20,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20/4969. 4949 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Tomates farcies aux restes de pot-au-feu.txt: 30it [00:22,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21/4969. 4948 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Soupe veloutée de potimarron et pommes de terre.txt: 56it [00:39,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22/4969. 4947 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from RISSOLES LORRAINES.txt: 29it [00:20,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23/4969. 4946 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Restes de pot au feu mijoté.txt: 21it [00:15,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24/4969. 4945 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Boulettes croustillantes (restes de pot-au-feu).txt: 26it [00:18,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25/4969. 4944 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Colombo de poulet facile.txt: 53it [00:36,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26/4969. 4943 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Chili rapide.txt: 29it [00:18,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27/4969. 4942 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Velouté de Potiron et Carottes.txt: 32it [00:23,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28/4969. 4941 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Colombo de poulet (Antilles).txt: 35it [00:23,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29/4969. 4940 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gratin de potiron et pommes de terre.txt: 28it [00:19,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30/4969. 4939 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Fajitas de poulet au Thermomix.txt: 33it [00:18,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31/4969. 4938 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Fajitas de poulet au Companion.txt: 29it [00:17,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 32/4969. 4937 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Velouté de potiron au Cookeo.txt: 31it [00:17,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 33/4969. 4936 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Fajitas de poulet au Cookeo.txt: 27it [00:18,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 34/4969. 4935 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gratin de potiron (avec astuce, pour éviter qu'il rende trop d'eau!).txt: 63it [00:40,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 35/4969. 4934 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Cari de poulet à la sauce tomate.txt: 59it [00:37,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 36/4969. 4933 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Crumble aux fruits sans farine et sans beurre.txt: 35it [00:24,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 37/4969. 4932 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gaufres (sans beurre).txt: 21it [00:15,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 38/4969. 4931 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Pancakes soufflés (Japan style).txt: 51it [00:30,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 39/4969. 4930 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Tarte au fromage blanc sans pâte (pour Flexipan).txt: 24it [00:17,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 40/4969. 4929 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Colombo de pommes de terre et choux fleur.txt: 30it [00:19,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 41/4969. 4928 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Pizza au fromage blanc.txt: 19it [00:13,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 42/4969. 4927 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Crèmes coco légères et rapides.txt: 25it [00:16,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 43/4969. 4926 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Bricks de pommes-poires ou dessert de carême amélioré.txt: 30it [00:18,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 44/4969. 4925 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Muffins au fromage et au jambon cru.txt: 37it [00:26,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 45/4969. 4924 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gâteaux aux noisettes.txt: 27it [00:17,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 46/4969. 4923 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Lentilles Antillaises.txt: 29it [00:19,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 47/4969. 4922 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Poulet Louisiane.txt: 44it [00:27,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 48/4969. 4921 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Cabri en colombo et sa sauce à la créole.txt: 55it [00:31,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 49/4969. 4920 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gâteau creusois.txt: 37it [00:24,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 50/4969. 4919 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Colombo de poulet antillais.txt: 43it [00:30,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 51/4969. 4918 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from charlotte choco coco crêpes dentelles.txt: 49it [00:36,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 52/4969. 4917 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gâteau au chocolat et aux noisettes.txt: 39it [00:31,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 53/4969. 4916 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Le trianon ou royal de Nadine.txt: 152it [01:16,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 54/4969. 4915 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Galette de kechek.txt: 44it [00:29,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 55/4969. 4914 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Sauce poule au pot de mamie Ginette.txt: 33it [00:22,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 56/4969. 4913 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Patates douces au gingembre et au piment.txt: 32it [00:22,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 57/4969. 4912 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Bûche à la framboise et à la pistache.txt: 25it [00:19,  1.31it/s]ERROR:root:File: Bûche à la framboise et à la pistache.txt, Pair: (Préchauffez, four), Error: 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Pr%C3%A9chauffez/to/four\n",
            "Processing pairs from Bûche à la framboise et à la pistache.txt: 26it [00:20,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing pair (Préchauffez, four): 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Pr%C3%A9chauffez/to/four\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Bûche à la framboise et à la pistache.txt: 81it [00:53,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 58/4969. 4911 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Brioche pain perdu.txt: 26it [00:19,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 59/4969. 4910 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Poulet au citron.txt: 47it [00:34,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 60/4969. 4909 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Poule au pot à l'ancienne.txt: 27it [00:17,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 61/4969. 4908 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Bûche framboise pistache.txt: 32it [00:22,  1.40it/s]ERROR:root:File: Bûche framboise pistache.txt, Pair: (Préchauffez, four), Error: 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Pr%C3%A9chauffez/to/four\n",
            "Processing pairs from Bûche framboise pistache.txt: 33it [00:23,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing pair (Préchauffez, four): 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Pr%C3%A9chauffez/to/four\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Bûche framboise pistache.txt: 82it [00:56,  1.35it/s]ERROR:root:File: Bûche framboise pistache.txt, Pair: (Placez, plat), Error: 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Placez/to/plat\n",
            "Processing pairs from Bûche framboise pistache.txt: 84it [00:57,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing pair (Placez, plat): 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Placez/to/plat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Bûche framboise pistache.txt: 92it [01:03,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 62/4969. 4907 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Poireaux à l'indienne.txt: 38it [00:23,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 63/4969. 4906 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Galette des rois pistache framboise.txt: 46it [00:31,  1.47it/s]ERROR:root:File: Galette des rois pistache framboise.txt, Pair: (disposer, veiller), Error: too many values to unpack (expected 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing pair (disposer, veiller): too many values to unpack (expected 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Galette des rois pistache framboise.txt: 75it [00:46,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 64/4969. 4905 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Croustades aux 3 fromages.txt: 24it [00:15,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 65/4969. 4904 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gâteau cagette de fruits de Véro les mains dans la farine.txt: 110it [01:15,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 66/4969. 4903 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from poulet kedjenou (Côte d'Ivoire).txt: 39it [00:24,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 67/4969. 4902 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Pâtes à la Portugaise de Belle Maman.txt: 54it [00:34,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 68/4969. 4901 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Salade de pourpier à la grecque.txt: 26it [00:17,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 69/4969. 4900 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Poulet au curry vert.txt: 26it [00:18,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 70/4969. 4899 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Salade de pourpier ou de mauve sauvage.txt: 69it [00:45,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 71/4969. 4898 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Poulpe grillé aux olives.txt: 69it [00:43,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 72/4969. 4897 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Salade de poulpe.txt: 49it [00:29,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 73/4969. 4896 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Poulpe \"a lagareiro\" (recette portugaise).txt: 63it [00:35,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 74/4969. 4895 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from salade de pourpier sauvage.txt: 30it [00:17,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 75/4969. 4894 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Poulpe à la gallego (poulpe de galice).txt: 51it [00:26,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 76/4969. 4893 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Salade de pourpier à l'huile de noix.txt: 21it [00:11,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 77/4969. 4892 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Pasta alla bottarga.txt: 41it [00:26,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 78/4969. 4891 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Salade pommes et feta (6ème rencontre).txt: 18it [00:12,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 79/4969. 4890 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Saumon à la Toscane au Airfryer.txt: 35it [00:24,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 80/4969. 4889 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Tartare de thon rouge à l'huile d'argan et à la boutargue.txt: 36it [00:23,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 81/4969. 4888 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Cataplana de poulet.txt: 44it [00:28,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 82/4969. 4887 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from PRAIRES FARCIES AUX NOIX ET AUX PIGNONS.txt: 30it [00:19,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 83/4969. 4886 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Potage pékinois au poulet.txt: 67it [00:46,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 84/4969. 4885 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Emincé de poulet aux pousses de bambou et poivron rouge.txt: 18it [00:12,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 85/4969. 4884 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Terrine de poisson et langoustine.txt: 67it [00:45,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 86/4969. 4883 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Ravioles ricotta épinards.txt: 37it [00:27,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 87/4969. 4882 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Papillotes de spaghetti aux fruits de mer.txt: 48it [00:31,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 88/4969. 4881 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Tarte aux pralines.txt: 29it [00:20,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 89/4969. 4880 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gâteau chocolat praliné.txt: 19it [00:14,  1.31it/s]ERROR:root:File: Gâteau chocolat praliné.txt, Pair: (gâteau, Préchauffez), Error: 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/g%C3%A2teau/to/Pr%C3%A9chauffez\n",
            "Processing pairs from Gâteau chocolat praliné.txt: 20it [00:15,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing pair (gâteau, Préchauffez): 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/g%C3%A2teau/to/Pr%C3%A9chauffez\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:File: Gâteau chocolat praliné.txt, Pair: (Préchauffez, four), Error: 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Pr%C3%A9chauffez/to/four\n",
            "Processing pairs from Gâteau chocolat praliné.txt: 21it [00:15,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing pair (Préchauffez, four): 500 Server Error: Internal Server Error for url: https://jdm-api.demo.lirmm.fr/v0/relations/from/Pr%C3%A9chauffez/to/four\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gâteau chocolat praliné.txt: 36it [00:26,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 90/4969. 4879 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Zarzuela maison.txt: 88it [00:54,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 91/4969. 4878 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Brioche de saint genix.txt: 45it [00:29,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 92/4969. 4877 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Paris-Brest praliné.txt: 78it [00:50,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 93/4969. 4876 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Cake aux pralines roses.txt: 30it [00:20,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 94/4969. 4875 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gâteau pralin rapide.txt: 35it [00:25,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 95/4969. 4874 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Brioche aux pralines rouges.txt: 24it [00:15,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 96/4969. 4873 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Coquillages gratinés au beurre anisé.txt: 24it [00:16,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 97/4969. 4872 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Émincé végétal à la sauce tomate.txt: 25it [00:17,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 98/4969. 4871 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Tarte bressane.txt: 47it [00:30,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 99/4969. 4870 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Crème pralinée onctueuse.txt: 22it [00:16,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 100/4969. 4869 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Rouleaux de printemps végétariens.txt: 69it [00:44,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 101/4969. 4868 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Boeuf Wellington  au Airfryer.txt: 100it [01:07,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 102/4969. 4867 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Croquant au chocolat.txt: 38it [00:28,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 103/4969. 4866 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Délice Choco-Poires Croustillant Praliné.txt: 111it [01:21,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 104/4969. 4865 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Gratin de chou-fleur végétarien.txt: 56it [00:38,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 105/4969. 4864 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Bolognaise végétarienne au soja.txt: 43it [00:29,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 106/4969. 4863 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Confiture de prunes d'ente.txt: 39it [00:25,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 107/4969. 4862 files left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing pairs from Clafoutis aux prunes reines-claude.txt: 15it [00:11,  1.30it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-744f5cc815b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mTHRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{BASE_URL}/from/{head}/to/{lemma}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relations\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;31m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mserver_hostname_rm_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mcert_reqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcert_reqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[0;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0mserver_hostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     ssl_sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mkeyfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpn_protocols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALPN_PROTOCOLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0mssl_sock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ssl_wrap_socket_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mssl_sock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSSLTransport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# SSLSocket class handles server_hostname encoding before it calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mserver_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_side\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "\n",
        "BASE_URL = \"https://jdm-api.demo.lirmm.fr/v0/relations\"\n",
        "\n",
        "# Configure logging\n",
        "log_file_path = os.path.join(PATH_OUTPUT, 'jdm_errors.log')\n",
        "logging.basicConfig(filename=log_file_path, level=logging.ERROR,\n",
        "                    format='%(asctime)s - %(levelname)s - %(filename)s - %(message)s')\n",
        "\n",
        "processed_files = [os.path.basename(f).replace(\"_relations.csv\", \".txt\")\n",
        "                   for f in glob.glob(os.path.join(PATH_OUTPUT + \"relations\", \"*_relations.csv\"))]\n",
        "print(processed_files)\n",
        "\n",
        "# Get total number of files\n",
        "total_files = len(glob.glob(os.path.join(PATH_DONNEES_BRUTES, \"*.txt\")))\n",
        "processed_count = 0  # Initialize processed file counter\n",
        "\n",
        "# MAIN LOOP\n",
        "for filename in glob.glob(os.path.join(PATH_DONNEES_BRUTES, \"*.txt\")):\n",
        "    # Extract filename without extension for comparison\n",
        "    base_filename = os.path.basename(filename)\n",
        "    if base_filename in processed_files:\n",
        "        print(f\"Skipping already processed file: {filename}\")\n",
        "        continue  # Skip to the next file\n",
        "\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Process the content of each file as before\n",
        "    sents = annotate(content)\n",
        "    all_pairs = []\n",
        "    for sent in sents:\n",
        "        p = extract_pairs(sent)\n",
        "        all_pairs.append(p)\n",
        "\n",
        "    filtered = []\n",
        "    for i, pair in enumerate(all_pairs):\n",
        "        for h, lemma, dep, pos in pair:\n",
        "            if h in model and lemma in model:\n",
        "                vec = pair_vector(h, lemma)\n",
        "                sim = cosine_sim(domain_centroid, vec)\n",
        "                filtered.append((h, lemma, dep, pos, sim))\n",
        "\n",
        "    seen_pairs = set()  # Keep track of pairs we've already written\n",
        "    # Create the directory if it doesn't exist\n",
        "    pairs_output_dir = os.path.join(PATH_OUTPUT, 'pairs')\n",
        "    relations_output_dir = os.path.join(PATH_OUTPUT, 'relations')\n",
        "    os.makedirs(pairs_output_dir, exist_ok=True)\n",
        "    os.makedirs(relations_output_dir, exist_ok=True)\n",
        "\n",
        "    output_filename_pairs = os.path.join(pairs_output_dir, os.path.basename(filename).replace(\".txt\", \"_pairs.txt\"))\n",
        "\n",
        "    with open(output_filename_pairs, \"w\") as f:\n",
        "        for h, lemma, dep, pos, sim in filtered:\n",
        "            pair = (h, lemma)\n",
        "            if pair not in seen_pairs:\n",
        "                f.write(f\"{h},{lemma},{dep},{pos},{sim}\\n\")\n",
        "                seen_pairs.add(pair)\n",
        "\n",
        "    # Example:  Adapt the JDM relation extraction\n",
        "    output_filename_relations = os.path.join(relations_output_dir, os.path.basename(filename).replace(\".txt\", \"_relations.csv\"))\n",
        "\n",
        "    with open(output_filename_pairs, encoding=\"utf-8\") as fin, \\\n",
        "        open(output_filename_relations, \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
        "\n",
        "        writer = csv.DictWriter(fout, fieldnames=[\"node1\",\"node2\",\"relations\"])\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Wrap the loop with tqdm to create a progress bar\n",
        "        for line in tqdm(fin, desc=f\"Processing pairs from {os.path.basename(filename)}\"): # use file name in the description\n",
        "            try:\n",
        "                head, lemma, dep, pos, sim = line.strip().split(\",\")\n",
        "                sim = float(sim)\n",
        "                if sim >= THRESHOLD:\n",
        "                    resp = requests.get(f\"{BASE_URL}/from/{head}/to/{lemma}\")\n",
        "                    resp.raise_for_status()\n",
        "                    rels = resp.json().get(\"relations\", [])\n",
        "                    writer.writerow({\n",
        "                        \"node1\": head,\n",
        "                        \"node2\": lemma,\n",
        "                        \"relations\": json.dumps(rels, ensure_ascii=False),\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                logging.error(f\"File: {os.path.basename(filename)}, Pair: ({head}, {lemma}), Error: {e}\")\n",
        "                print(f\"Error processing pair ({head}, {lemma}): {e}\")\n",
        "    processed_count += 1  # Increment processed file counter\n",
        "    print(f\"Processed {processed_count}/{total_files}. {total_files - processed_count} files left.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lAEKNygpVEZ"
      },
      "source": [
        "# Approche initiale (Ça sert à rien pour vous)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYDEjPsxfVtF",
        "outputId": "8b830d8c-aecf-4c3d-da73-dd81832071d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "my_local_drive='/content/gdrive/My Drive/TER/'\n",
        "sys.path.append(my_local_drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq98sQiLO3mp"
      },
      "outputs": [],
      "source": [
        "PATH_RELATIONS_TYPES = f\"{my_local_drive}relations_types.json\" # Liste des relations\n",
        "PATH_PAIRS = f\"{my_local_drive}pairs.txt\" # Paires récupérées\n",
        "PATH_FILTERED_PAIRS = f\"{my_local_drive}filtered_pairs.txt\" # Paires filtrées par Word2Vec\n",
        "PATH_UNDER_PAIRS = f\"{my_local_drive}under_threshold_pairs.txt\"\n",
        "PATH_RELATIONS_RESULTS = f\"{my_local_drive}relations_results.csv\" # Résultats retournés de JdM\n",
        "\n",
        "CURR_FOLDER = \"wikipedia/\"\n",
        "PATH_DONNEES_BRUTES = f\"{my_local_drive}donnees_brutes/{CURR_FOLDER}\"\n",
        "PATH_OUTPUT = f\"{my_local_drive}output/{CURR_FOLDER}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo-EAPmjzwh0"
      },
      "outputs": [],
      "source": [
        "# !pip install wikipedia-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLsPnejMhTOi"
      },
      "outputs": [],
      "source": [
        "# import wikipediaapi\n",
        "# import re\n",
        "# from urllib.parse import unquote\n",
        "\n",
        "# # url = \"https://fr.wikipedia.org/wiki/Pot-au-feu\"  # Change this to any Wikipedia URL\n",
        "# url = \"https://fr.wikipedia.org/wiki/Tripes_%C3%A0_la_proven%C3%A7ale\"\n",
        "\n",
        "# def get_wikipedia_text(url, lang='fr'):\n",
        "#     # Extract the title from the Wikipedia URL\n",
        "#     decoded_url = unquote(url)\n",
        "#     match = re.search(r\"/wiki/(.+)$\", decoded_url)\n",
        "#     if not match:\n",
        "#         print(\"Invalid Wikipedia URL.\")\n",
        "#         return None\n",
        "\n",
        "#     page_title = match.group(1).replace('_', ' ')\n",
        "\n",
        "#     wiki_wiki = wikipediaapi.Wikipedia(language=lang, user_agent=\"MyWikipediaScraper/1.0\")\n",
        "#     page = wiki_wiki.page(page_title)\n",
        "\n",
        "#     if not page.exists():\n",
        "#         print(f\"Page '{page_title}' does not exist.\")\n",
        "#         return None\n",
        "\n",
        "#     return page.text\n",
        "\n",
        "# text = get_wikipedia_text(url)\n",
        "\n",
        "# # Save to a text file\n",
        "# if text:\n",
        "#     with open(f\"{my_local_drive}wikipedia_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "#         f.write(text)\n",
        "#     print(f\"Text saved to wikipedia_text.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLUPnr3QjxIt"
      },
      "outputs": [],
      "source": [
        "# content = \"\"\n",
        "# with open(f\"{my_local_drive}wikipedia_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "#   content = f.read();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i9QYtQtqE70"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download fr_core_news_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIMlLE2ItHUn"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "import spacy\n",
        "nlp = spacy.load(\"fr_core_news_lg\")\n",
        "\n",
        "@dataclass\n",
        "class TokenAnnotation:\n",
        "    text: str           # surface form\n",
        "    lemma: str          # canonical form\n",
        "    pos: str            # part-of-speech tag\n",
        "    dep: str            # dependency label\n",
        "    head: int           # index of the head token in its sentence\n",
        "    sent_id: Optional[int] = None  # optional: which sentence\n",
        "\n",
        "def annotate(text: str) -> List[List[TokenAnnotation]]:\n",
        "    doc = nlp(text)\n",
        "    all_sents: List[List[TokenAnnotation]] = []\n",
        "    for sent_id, sent in enumerate(doc.sents):\n",
        "        tokens = []\n",
        "        for token in sent:\n",
        "            tokens.append(TokenAnnotation(\n",
        "                text=token.text,\n",
        "                lemma=token.lemma_,\n",
        "                pos=token.pos_,\n",
        "                dep=token.dep_,\n",
        "                head=token.head.i - sent.start,  # index *within* this sentence\n",
        "                sent_id=sent_id\n",
        "            ))\n",
        "        all_sents.append(tokens)\n",
        "    return all_sents\n",
        "\n",
        "# Exécution\n",
        "# Utiliser ça au lieu du texte brut de Wikipedia pour tester\n",
        "# test_text = \"\"\"Le pot-au-feu (inv.) est une recette de cuisine traditionnelle emblématique historique de la cuisine française, et du repas gastronomique des Français, à base de viande de bœuf cuisant longuement à feu très doux dans un bouillon de légumes (poireau, carotte, navet, oignon, céleri, chou et bouquet garni). La présence de pommes de terre est discutée, puisqu’elles ne faisaient pas partie de la recette d’origine, la pomme de terre n’ayant été introduite en France par Antoine Parmentier qu’à la fin du XVIIIe siècle. Historiquement, c’est plutôt le panais qui jouait son rôle.\n",
        "# Historique\n",
        "# Jean Louis Schefer fait remonter le pot-au-feu au rêve néolithique, « celui du foyer, du vase d'argile, du pot mis au feu, de la soif étanchée, de la faim apaisée… », origine reprise par le restaurant À la Cloche d'or : « Pot-au-feu désigne à la base le « pot à feu », le pot dans lequel on faisait revenir un bouillon aromatique auquel on ajoutait viandes et légumes ». Jean Guillaume pense qu'à l'origine de l'agriculture les raves sont venues compléter les herbes dans les bouillons, « on y ajoutait du pain pour faire la soupe et de la viande pour les grands jours ».\n",
        "# Au XIIIe siècle, il est appelé « viande au pot ». Autrefois, la cuisson du pot-au-feu pouvait s’effectuer de façon continue, de nouveaux ingrédients étant rajoutés au fur et à mesure pour remplacer ceux qui étaient retirés afin d’être consommés. À présent que les maisons n’ont plus un feu de bois allumé en continu, le pot-au-feu est cuisiné spécifiquement en vue d’un repas.\n",
        "# Marcel Rouff, dans son roman Vie et Passion de Dodin-Bouffant, gourmet (1924) a décrit un pot-au-feu devenu mythique, qui a inspiré des pots-au-feu démesurés à de nombreux chefs.\n",
        "# Composition\n",
        "# Les coupes de bœuf et les légumes impliqués varient, mais un pot-au-feu typique contient :\n",
        "# des coupes de bœuf à faible coût nécessitant une longue cuisson : gîte, gîte à la noix, joue de bœuf, jarret, plat de côtes, paleron, macreuse à pot-au-feu ou jumeau à pot-au-feu ;\n",
        "# classiquement fait avec du bœuf ou du poulet, parfois veau, porc ou mouton sont utilisés ;\n",
        "# un ou plusieurs morceaux cartilagineux : queue de bœuf ou os à moelle ;\n",
        "# des légumes : carotte, navet, poireau, parfois pomme de terre (qui n’a été introduite que tard, au cours du XVIIIe siècle au moment de sa promotion en France par Antoine Parmentier), céleri-rave, oignon (selon les régions et les recettes) ;\n",
        "# des épices : bouquet garni, sel, poivre noir et clous de girofle.\n",
        "# Le pot-au-feu est l'un des rares plats où l'on utilise parfois des aliments brûlés : pour parfumer et colorer le bouillon, les oignons sont coupés en deux et passés au four (gril) jusqu'à ce que la surface soit complètement noire.\n",
        "# Jules Gouffé, cuisinier et pâtissier français du XIXe siècle distingue le petit pot-au-feu ordinaire du grand pot-au-feu des jours d'extra.\n",
        "# Cuisson\n",
        "# Deux méthodes sont en présence : mettre le bœuf dans l'eau froide ou bien dans l'eau bouillante. La première donne un bouillon succulent, la seconde préserve davantage le gout des viandes. Paul Bocuse, Jules Gouffé optent  pour l'eau froide. Un bon compromis selon Sabine Jeannin et al. est de commencer à l'eau froide avec un premier morceau de bœuf, et d'en ajouter un autre quand l'eau bout.\n",
        "# Le bouillon contient traditionnellement un oignon piqué de clous de girofle, l'ail est déconseillé. La cuisson doit être longue et douce, (« le premier soin est de bien faire son feu »), ébullition continue et régulière pendant 3 à 5 heures selon le contenu, trop cuire le pot-au-feu est néfaste — les légumes ne séjournent dans le bouillon que le temps de les cuire —, on laisse entrouvert le couvercle de la marmite. Le bouillon est écumé en début de cuisson puis dégraissé après avoir retiré la viande cuite. Les amateurs préfèrent le pot-au-feu réchauffé le lendemain.\n",
        "# Dans les autocuiseurs, la cuisson se fait toujours en deux temps, le second est bref et réservé aux légumes.\n",
        "# Service\n",
        "# Le bouillon de cuisson du pot-au-feu est servi à côté comme potage, souvent agrémenté de pâtes, riz ou pain grillé, au dîner ou en entrée avant de servir la viande et les légumes du pot-au-feu. Il sert également de base aux sauces ou à la cuisson des légumes ou des pâtes. La moelle est mangée sur du pain grillé. Ensuite, le pot-au-feu est généralement servi avec du gros sel et de la moutarde forte de Dijon. Le reste de viande peut être broyé et utilisé pour la préparation d'un pâté de viande, mais cette pratique est rare en France, sauf en Alsace où la viande et le bouillon servent à cuisiner les Fleischschnacka.\n",
        "# Accord mets/vin\n",
        "# Le vin blanc est rarement proposé avec le pot-au-feu. Il s'accorde pourtant avec ce mets s'il est ample et vif, dans ce cas, c'est un vin qui désaltère et met en appétit.\n",
        "# Le vin rosé à conseiller doit être sec, corsé, avec une robe rose-rouge qui témoigne de sa charge en matières sèches. Ce type de vin s'accorde avec les légumes et étanche la soif.\n",
        "# Le vin rouge offre une large gamme qui va des bourgognes aux bordeaux, en passant par les beaujolais, les côtes-du-rhône-villages, les coteaux-du-languedoc,.\"\"\"\n",
        "\n",
        "# sents = annotate(test_text)\n",
        "# for sent in sents:\n",
        "#     print(sent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQw_0tpYQW8U"
      },
      "source": [
        "Approche initiale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAjlOMhy1Xl0"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy\n",
        "tesssst = nlp(\"Le bouillon contient traditionnellement un oignon piqué de clous de girofle, l'ail est déconseillé.\")\n",
        "displacy.serve(tesssst, style=\"dep\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GsJAI7v18CV"
      },
      "outputs": [],
      "source": [
        "POUR VOIR LES EXPLICATIONS DES LABELS `dep`\n",
        "for label in nlp.get_pipe(\"parser\").labels:\n",
        "    print(label, \" -- \", spacy.explain(label))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzNkaOEb93eD"
      },
      "source": [
        "Explication des DEPS intéressés\n",
        "\n",
        "  1.\tDepLabel : nsubj\n",
        "\t•\tPourquoi : lie un verbe à son sujet (agent)\n",
        "\t•\tExemple & paire extraite : « Le pot-au-feu est une recette. » → (recette, pot-au-feu)\n",
        "\n",
        "  2.\tDepLabel : nsubj:pass\n",
        "\t•\tPourquoi : lie un verbe passif à son sujet/patient\n",
        "\t•\tExemple & paire extraite : « La présence de pomme de terre est discutée. » → (discutée, présence)\n",
        "\n",
        "  3.\tDepLabel : obj\n",
        "\t•\tPourquoi : lie un verbe à son objet direct (quoi fait-on ?)\n",
        "\t•\tExemple & paire extraite : « Schefer fait remonter le pot-au-feu. » → (remonter, pot-au-feu)\n",
        "\n",
        "  4.\tDepLabel : iobj\n",
        "\t•\tPourquoi : lie un verbe à son objet indirect (qui reçoit l’action)\n",
        "\t•\tExemple & paire extraite : « un bouillon auquel on ajoutait viandes. » → (ajoutait, auquel)\n",
        "\n",
        "  5.\tDepLabel : nmod\n",
        "\t•\tPourquoi : complément nominal via préposition (“de”, “à”, …)\n",
        "\t•\tExemple & paire extraite : « recette de cuisine » → (recette, cuisine)\n",
        "\n",
        "  6.\tDepLabel : obl\n",
        "\t•\tPourquoi : complément oblique (lieu, instrument, but…)\n",
        "\t•\tExemple & paire extraite : « cuisant à feu doux » → (cuisant, feu)\n",
        "\n",
        "  7.\tDepLabel : amod\n",
        "\t•\tPourquoi : lie un nom à son adjectif qualificatif\n",
        "\t•\tExemple & paire extraite : « recette traditionnelle » → (recette, traditionnelle)\n",
        "\n",
        "  8.\tDepLabel : compound\n",
        "\t•\tPourquoi : reconstitue des termes composés (expressions figées)\n",
        "\t•\tExemple & paire extraite : « pot-au-feu » → (pot-au-feu, feu)\n",
        "\n",
        "  9.\tDepLabel : flat:name\n",
        "\t•\tPourquoi : agrège des noms propres formant une seule entité\n",
        "\t•\tExemple & paire extraite : « Jean Louis Schefer » → (Jean, Louis)\n",
        "\n",
        "  10.\tDepLabel : appos\n",
        "\t•\tPourquoi : apposition — le second nom renomme le premier\n",
        "\t•\tExemple & paire extraite : « bouillon, poireau, carotte… » → (bouillon, poireau)\n",
        "\n",
        "  11.\tDepLabel : acl\n",
        "\t•\tPourquoi : clause participiale attachée à un nom\n",
        "\t•\tExemple & paire extraite : « pot mis au feu » → (pot, mis)\n",
        "\n",
        "  12.\tDepLabel : acl:relcl\n",
        "\t•\tPourquoi : proposition relative attachée à un nom\n",
        "\t•\tExemple & paire extraite : « le panais qui jouait son rôle » → (panais, jouait)\n",
        "\n",
        "  13.\tDepLabel : advcl\n",
        "\t•\tPourquoi : clause adverbiale attachée à un verbe\n",
        "\t•\tExemple & paire extraite : « le bouillon contient … l’ail est déconseillé » → (contient, déconseillé)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQgKuDRYCXzB"
      },
      "outputs": [],
      "source": [
        "INTERESTING_DEPS = {\n",
        "    # verbal relations: subject → verb, verb → object\n",
        "    \"nsubj\", \"nsubj:pass\", \"obj\", \"iobj\",\n",
        "    # noun modifiers: noun → noun (prep-headed), noun → adjective\n",
        "    \"nmod\", \"obl\",  \"amod\",    # e.g. “recette de cuisine”, “bouillon aromatique”\n",
        "    # multi-word names & appositions\n",
        "    \"compound\", \"flat:name\", \"appos\",\n",
        "    # clausal modifiers (relative/participial clauses)\n",
        "    \"acl\", \"acl:relcl\", \"advcl\",\n",
        "}\n",
        "\n",
        "def extract_pairs(tokens):\n",
        "    pairs = []\n",
        "    for idx, tok in enumerate(tokens):\n",
        "        if tok.dep in INTERESTING_DEPS:\n",
        "            head = tokens[tok.head]\n",
        "            pairs.append(( head.lemma, tok.lemma, tok.dep, tok.pos ))\n",
        "    return pairs\n",
        "\n",
        "# all_pairs = []\n",
        "# for sent in sents:\n",
        "#     p = extract_pairs(sent)\n",
        "#     all_pairs.append(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Gx6FdiIfUDBd",
        "outputId": "25e10f16-4930-49a0-9ef9-92b541c277bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HEAD | LEMMA | DEP | POS\n",
            "('recette', 'pot-au-feu', 'nsubj', 'NOUN')\n",
            "('pot-au-feu', 'inv', 'appos', 'NOUN')\n",
            "('recette', 'cuisine', 'nmod', 'NOUN')\n",
            "('cuisine', 'traditionnel', 'amod', 'ADJ')\n",
            "('cuisine', 'emblématique', 'amod', 'ADJ')\n",
            "('recette', 'historique', 'amod', 'NOUN')\n",
            "('cuisine', 'français', 'amod', 'ADJ')\n",
            "('repas', 'gastronomique', 'amod', 'ADJ')\n",
            "('repas', 'français', 'nmod', 'NOUN')\n",
            "('repas', 'base', 'nmod', 'NOUN')\n",
            "('base', 'viande', 'nmod', 'NOUN')\n",
            "('viande', 'bœuf', 'nmod', 'NOUN')\n",
            "('base', 'cuire', 'acl', 'VERB')\n",
            "('feu', 'doux', 'amod', 'ADJ')\n",
            "('repas', 'bouillon', 'nmod', 'NOUN')\n",
            "('bouillon', 'légume', 'nmod', 'NOUN')\n",
            "('repas', 'poireau', 'appos', 'NOUN')\n",
            "('repas', 'navet', 'appos', 'NOUN')\n",
            "('bouquet', 'garni', 'amod', 'ADJ')\n"
          ]
        }
      ],
      "source": [
        "print(f\"HEAD | LEMMA | DEP | POS\")\n",
        "for i, pair in enumerate(all_pairs[:1]):\n",
        "    for p in pair: print(p)\n",
        "\n",
        "with open(PATH_PAIRS, \"w\") as f:\n",
        "    for i, pair in enumerate(all_pairs):\n",
        "        for p in pair:\n",
        "            f.write(f\"{p[0]},{p[1]},{p[2]},{p[3]}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc01qm8dKnVI"
      },
      "outputs": [],
      "source": [
        "# with open(PATH_PAIRS, \"r\", encoding=\"utf-8\") as f:\n",
        "#     candidate_pairs = [tuple(line.strip().split(\",\"))\n",
        "#                        for line in f\n",
        "#                        if line.strip()]\n",
        "# print(f\"Loaded {len(candidate_pairs)} candidate pairs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq4_-AUNQoko",
        "outputId": "697a260f-d5ce-41de-edf3-3fb979cdd168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ],
      "source": [
        "# !pip install numpy==1.24.3 --force-reinstall # Downgrade numpy to a version compatible with gensim\n",
        "!pip install --upgrade gensim --force-reinstall # Reinstall gensim with the compatible numpy version\n",
        "# !pip install --upgrade scipy --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFAGmfi7RydO",
        "outputId": "24562fac-a7a0-48bf-e982-1f182522a7db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-12 15:41:40--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.238.176.44, 18.238.176.19, 18.238.176.115, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.238.176.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1287757366 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.fr.300.vec.gz’\n",
            "\n",
            "cc.fr.300.vec.gz     26%[====>               ] 322.68M   114MB/s               ^C\n"
          ]
        }
      ],
      "source": [
        "# Run this if model is not downloaded\n",
        "!wget -c \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz\" -O \"cc.fr.300.vec.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i68d4CjMVL3n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "from numpy.linalg import norm\n",
        "from collections import defaultdict\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('cc.fr.300.vec.gz', binary=False, limit=50000)  # Limit to 50k for memory\n",
        "\n",
        "# 1. Define your gastronomy “pivot” words\n",
        "pivots = [\"cuisine\",\"recette\",\"ingrédient\",\"épice\",\"gastronomie\"]\n",
        "# Keep only those that actually exist in the model\n",
        "pivot_vecs = [model[p] for p in pivots if p in model]\n",
        "if not pivot_vecs:\n",
        "    raise ValueError(\"None of your pivots were in the model!\")\n",
        "\n",
        "# 2. Compute the domain centroid\n",
        "domain_centroid = np.mean(pivot_vecs, axis=0)\n",
        "\n",
        "\n",
        "# 3. Load your candidate pairs (head, dependent)\n",
        "#    For example, from your pairs.txt:\n",
        "pairs = []\n",
        "with open(PATH_PAIRS, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        h, lemma, dep, pos = line.strip().split(\",\")\n",
        "        pairs.append((h, lemma, dep, pos))\n",
        "\n",
        "\n",
        "# 4. Define helper functions\n",
        "def pair_vector(h, lemma):\n",
        "    \"\"\"Average the two word vectors.\"\"\"\n",
        "    return (model[h] + model[lemma]) / 2\n",
        "\n",
        "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    return float(a.dot(b) / (norm(a) * norm(b)))\n",
        "\n",
        "\n",
        "# 5. Compute similarities and filter\n",
        "THRESHOLD = 0.25\n",
        "filtered = []\n",
        "under_threshold = []\n",
        "for h, lemma, dep, pos in pairs:\n",
        "    if h in model and lemma in model:\n",
        "        vec = pair_vector(h, lemma)\n",
        "        sim = cosine_sim(domain_centroid, vec)\n",
        "        if sim >= THRESHOLD:\n",
        "            filtered.append((h, lemma, dep, pos, sim))\n",
        "        else:\n",
        "            under_threshold.append((h, lemma, dep, pos, sim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bJXhuruAV4dU"
      },
      "outputs": [],
      "source": [
        "# print(f\"Under threshold - removed {len(under_threshold)} pairs:\")\n",
        "# for h, lemma, dep, pos, sim in under_threshold:\n",
        "#     print(f\"  {h:12s} {lemma:12s} → sim={sim:.3f}\")\n",
        "\n",
        "# print(\"\\n---------------------\\n\")\n",
        "\n",
        "# print(f\"Kept {len(filtered)}/{len(pairs)} pairs:\")\n",
        "# for h, lemma, dep, pos, sim in filtered:\n",
        "#     print(f\"  {h:12s} {lemma:12s} → sim={sim:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB2vRML95z7B"
      },
      "outputs": [],
      "source": [
        "# Save unique pairs to filtered_pairs.txt\n",
        "seen_pairs = set()  # Keep track of pairs we've already written\n",
        "\n",
        "with open(PATH_FILTERED_PAIRS, \"w\") as f:\n",
        "    for h, lemma, dep, pos, sim in filtered:\n",
        "        pair = (h, lemma)\n",
        "        if pair not in seen_pairs:\n",
        "            f.write(f\"{h},{lemma},{dep},{pos},{sim}\\n\")\n",
        "            seen_pairs.add(pair)\n",
        "\n",
        "with open(PATH_UNDER_PAIRS, \"w\") as f:\n",
        "    for h, lemma, dep, pos, sim in under_threshold:\n",
        "        pair = (h, lemma)\n",
        "        f.write(f\"{h},{lemma},{dep},{pos},{sim}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "9rJ7pUb_mTbQ",
        "outputId": "886ffd3c-6fe2-427f-eb9e-d336181eccc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing pairs:   1%|          | 2/180 [00:01<02:07,  1.40it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9c3a2324fc75>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing pairs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{BASE_URL}/from/{head}/to/{lemma}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relations\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;31m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mserver_hostname_rm_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mcert_reqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcert_reqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[0;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0mserver_hostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     ssl_sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mkeyfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpn_protocols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALPN_PROTOCOLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0mssl_sock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ssl_wrap_socket_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mssl_sock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSSLTransport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# SSLSocket class handles server_hostname encoding before it calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mserver_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_side\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import requests, csv, json, time\n",
        "from tqdm import tqdm  # Import tqdm for the progress bar\n",
        "\n",
        "BASE_URL = \"https://jdm-api.demo.lirmm.fr/v0/relations\"\n",
        "INPUT    = PATH_FILTERED_PAIRS # filtered_pairs.txt\n",
        "OUTPUT   = PATH_RELATIONS_RESULTS # relations_results.csv\n",
        "\n",
        "# Count the total number of lines in the input file\n",
        "with open(INPUT, encoding=\"utf-8\") as fin:\n",
        "    total_lines = sum(1 for line in fin)\n",
        "\n",
        "with open(INPUT, encoding=\"utf-8\") as fin, \\\n",
        "     open(OUTPUT, \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
        "\n",
        "    writer = csv.DictWriter(fout, fieldnames=[\"node1\",\"node2\",\"relations\"])\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Wrap the loop with tqdm to create a progress bar\n",
        "    for line in tqdm(fin, total=total_lines, desc=\"Processing pairs\"):\n",
        "        head, lemma, dep, pos, sim = line.strip().split(\",\")\n",
        "        resp = requests.get(f\"{BASE_URL}/from/{head}/to/{lemma}\")\n",
        "        resp.raise_for_status()\n",
        "        rels = resp.json().get(\"relations\", [])\n",
        "        writer.writerow({\n",
        "            \"node1\": head,\n",
        "            \"node2\": lemma,\n",
        "            \"relations\": json.dumps(rels, ensure_ascii=False),\n",
        "        })\n",
        "        time.sleep(0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xlcLQ9or9FJ"
      },
      "source": [
        "**Preview results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZxUqkbPrPAQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(PATH_RELATIONS_RESULTS)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ─ Assumes you already have:\n",
        "#    df         = your DataFrame with columns ['node1','node2','relations']\n",
        "#    rel_types  = list of dicts loaded from relations_types.json\n",
        "\n",
        "# 1. Parse the JSON strings in 'relations'\n",
        "df['relations'] = df['relations'].apply(json.loads)\n",
        "\n",
        "# Load the CSV and JSON metadata\n",
        "with open(PATH_RELATIONS_TYPES, 'r', encoding='utf-8') as f:\n",
        "    rel_types = json.load(f)\n",
        "\n",
        "# 2. Explode & normalize into a flat DataFrame\n",
        "rel_df = pd.json_normalize(\n",
        "    df.explode('relations')['relations']\n",
        ").rename(columns={'type': 'rel_type', 'w': 'weight'})\n",
        "\n",
        "# 3. Compute aggregate stats\n",
        "stats = (\n",
        "    rel_df\n",
        "    .groupby('rel_type', as_index=False)\n",
        "    .agg(Count=('rel_type', 'size'),\n",
        "         Mean_w=('weight', 'mean'))\n",
        ")\n",
        "stats['% of total'] = stats['Count'] / stats['Count'].sum() * 100\n",
        "\n",
        "# 4. Build metadata DataFrame from rel_types\n",
        "meta_df = (\n",
        "    pd.DataFrame(rel_types)[['id','name','gpname']]\n",
        "    .rename(columns={'id':'rel_type','name':'Name','gpname':'Label'})\n",
        ")\n",
        "\n",
        "# 5. Merge, format, and select top 10\n",
        "merged = stats.merge(meta_df, on='rel_type').sort_values('Count', ascending=False)\n",
        "merged['Mean_w']     = merged['Mean_w'].round(2)\n",
        "merged['% of total'] = merged['% of total'].round(1)\n",
        "top10 = merged.head(10)[['rel_type','Name','Label','Count','% of total','Mean_w']]\n",
        "\n",
        "# 6. Display results\n",
        "print(top10.to_string(index=False))\n",
        "\n",
        "# 7. Visualize\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(top10['Name'], top10['Count'])\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel('Nombre de relations')\n",
        "plt.title('Top 10 des types de relations par fréquence')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN3mV8ZidnWtAtYC2/PS8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}